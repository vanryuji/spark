PySpark on PyCharm

# Environments
* macOS Mojave 10.14.4<br>
* PyCharm Community 2019.1<br>
* PySpark 2.4.2 <br>
* Oracle Java 12<br>
* Python 2.7.10<br>

# PyCharm setup
1. Python Interpreter
![alt text](interpreter.png)

2. Environment Variables
![alt text](environment_variables.png)

# TODO
* PyCharm runs application as 'python my_app.py', but Spark example(https://spark.apache.org/docs/latest/streaming-programming-guide.html) says 'spark-submit my_app.py'<br>
What is difference between them??
